

### 微服务四大技术难点

1. 数据一致性分发：
    * 当服务产生了新数据，除了在保存当前服务数据库外，还需要更新Redis缓存，同步到其他服务，同步到数据仓库等等。
    * 如果各个功能采用poll模式进行拉取，一是数据可能不实时，二是频繁的poll也会造成分发服务器的性能问题。所以还是分发服务push到感兴趣的服务。
    <div style="width:230px;height:230px;display:flex;justify-content:center;align-items:center;">
    <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257246718076.jpg" />
</div>


        
2. 数据聚合Join
    在单体架构下，存在的数据库join问题，其实带来性能问题是很严重的。
    > 1.会对Join的驱动表做全表扫描，导致冷数据污染buffer pool，进而其他请求需要读磁盘，因此系统响应变慢，大部分请求阻塞。
    
    > 2.如果业务采用select *作为结果集返回，极大可能出现网络拥堵，整体拖慢服务端的处理；
    
    在分布式服务情况下，Join的问题其实还没有消失。
    ![-w368](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257074613896.jpg)
    > 1.N+1问题，比如有可能用户服务只查询一次，但是订单服务查询了N次。
    
    > 2.进行Join会把大量的数据加载到本地内存中，甚至撑爆服务。
    
    > 3.如果没有缓存的情况下，那么每次调用接口查询，都会进行聚合运算，效率低下。


1. 分布式事务
在单库情况下，已经有很成熟的机制，可以很好的支持ACID，保证了单机事务。
而在分布式情况下，业务需要同时操作两个服务，每个服务都有自己的数据库，那如何保证分布式事务呢？
![-w1150](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257079088166.jpg)


4. 单体系统解耦拆分
如果将一个单体系统平滑的拆分成微服务架构？

针对上述四个问题，我们一起来寻找最适合的方案。

### 问题1：数据一致性分发

![-w646](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257154392383.jpg)
在上图可以看出，在合同系统中放款的处理流程：
* 同步保存自己单独数据库
* 分发数据到不同的系统模块中

根据上述的描述，这里有个问题？如何保证DB操作和分发数据的原子性，如果无法保证事务性，那么就可能造成数据的不一致：
<div style="width:500px;height: 300px;display:flex;justify-content:center;align-items:center;">
    <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257156791411.jpg" />
</div>

如果你考虑使用双写的模式来解决这个问题，如下示例代码：
<div style="width:350px;height: 300px;display:flex;justify-content:center;align-items:center;">
    <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257159518479.jpg" />
</div>
那么很遗憾，这样的方式是无法解决的，图中第3步发送消息的时候还是有问题，我们要有一个认知，就是网络是不可靠的，如果网络出现故障，还是无法保证事务性。

##### 解法方案
这里提供两个解决方案供你选择，1、事务发件箱(Transaction OutBox) 2、变更数据捕获(Change Data Capture ,CDC)，我先来介绍下两种方案和相关的落地实现，最后再来一起看下选择哪种解决方案。

1. 事务发件箱(Transaction OutBox)
    <div style="width:500px;height: 500px;display:flex;justify-content:center;align-items:center;">
        <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257252330908.jpg" />
    </div>
      
    该方案的主要流程：
    * 在第一步的时候，在当前数据库里的业务表操作业务数据 并且 在发件箱表里插入要发送的数据。因为是在同一数据库下，可以保证事务性。
    
    * 在第二步，会有一个消息中继轮询的去读发件箱里的数据。
    
    * 第三步就是把消息发送给MQ，这里需要注意的是因为网络抖动，当发送消息失败的时候，需要一定次数的重发消息机制，实现At least once (至少一次)语义，另外，因为At least once的语义，也需要在消息消费端做幂等处理。
    
    该方案落地的开源框架 : [Killbill Common Queue](https://github.com/killbill/killbill-commons/tree/master/queue)

1. 变更数据捕获(Change Data Capture ,CDC)

    CDC，在我们项目中经常会听到，但是很多人对它不熟悉，那和我一起看一下它能做什么。
首先从CDC名字来看，就是捕获那些产生了变更的数据。那么如何捕获？该捕获哪些呢？

    <div style="width:500px;height: 500px;display:flex;justify-content:center;align-items:center;">
        <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257262290018.jpg" />
    </div>
    
    在上图中，可以看出：
    * 第一步，order表发生了DML操作后，那么Transactiong log(例如mysql中的binlog日志)日志就会记录其的变化。
    
    * 第二步，这里需要一个miner用来捕获Transactiong log日志的变化，这个就是CDC。
    * 第三部，miner把消息发送给MQ，这里也是At least once (至少一次)语义。

    该方案落地的开源框架 : [阿里的Canal](https://github.com/alibaba/canal)

1. Eventuate Tram
    上面说了两种方案，在我们项目中采用的是Eventuate Tram框架，这个框架是Chris Richardson大牛搞出来的，也是微服务架构设计的作者，这个框架实现了DDD、CQRS、事件溯源、saga、cdc等。所以在我们项目中使用的是CDC，可以看下图：
    
    <div style="width:500px;height: 500px;display:flex;justify-content:center;align-items:center;">
        <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257273194887.jpg" />
    </div>
  
     Github地址：[eventuate-tram-core](https://github.com/eventuate-tram/eventuate-tram-core)
     
1. 最后来比较下两种方案
    
    |  | Transaction OutBox | CDC |
    | --- | --- | --- |
    | 复杂性  | 相对简单些 | 比较复杂(需要高可用/监控) |
    | 耦合性 | 耦合 | 无侵入 |
    | 延迟和性能 | 近实时，有一定性能开销 | 比较实时，性能开销小 |
    | 适用场景 | 中小规模 | 中大规模，需要独立的框架治理团队 |

 
### 问题2：数据聚合Join

<div style="width:300px;height: 300px;display:flex;justify-content:center;align-items:center;">
        <img src="https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257074613896.jpg" />
    </div>

接着来解决数据聚合Join的问题，看上图，用户系统是单独的数据库，订单系统也是单独的数据库，那么现在有个API查询用户订单，我们可以称查询服务这一层是Aggregator。它负责将两个不同服务的数据聚合在一起返回。

我先说解决方案，就比如用户订单，需要查询用户和订单两个系统，那么我们可以反正规化的数据查询，具体就是采用 数据分发 + 物化视图来解决。
* 数据分发，我们刚才已经讨论了，就是发生变化的时候，进行数据分发到需要的系统中。
* 物化视图是指，在查询用户订单的服务中，将用户和订单的数据保存下来，比如存在Redis、Mysql等中，当进行数据查询的时候就直接从这里取数据，而不是调用不同服务进行查询再聚合在一起。

上面这个方案还有一个时髦的名字叫做CQRS：
![-w1303](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257298090653.jpg)
当业务数据发生变化时，采用数据分发的方式到不同的读取端，这些读取端从自己保存的数据进行查询返回。

这里你可能就要问了，如果因为网络等问题导致，实时更新的数据库和近实时的读取端的数据没有及时一致该怎么办？

先说下，CQRS强调的是最终一致性，在分布式系统CAP理论和BASE理论的指导下，通过业务牺牲强一致性而获得可用性，并允许数据在一段时间内是不一致的，但是最终达到一致性状态。这是常用的做法。

所以，下面我要介绍的是，读取端获取数据的几种模式：
1. 乐观更新：例如点赞等简单场景，前端直接修改前端展示，用户感知已经点赞成功，后台在进行命令，如果后台执行失败，回滚前端状态即可。
2. 拉模式：前端进行查询请求时带上一个版本号，直到在读取端找到对应版本的数据再返回。
3. 发布订阅模式：前端请求查询，订阅到读取端的事件，等待读取端的发布时间。

上面讨论了CQRS，其实需要的技术门槛挺高的，所以需要选择是否使用。

### 问题3：分布式事务

分布式事务是本文的重头戏，能说的太多了，我这里就挑关键的部分分享给大家。
首先先介绍下ACID和事务的隔离级别。
##### ACID
先来看下数据库事务的 ACID， 这四大特性是事务的基础：
* A (Atomicity  原子性)
    * 原子性：事务就是一系列的操作，要么全部都执行，要么全都不执行；
    * 如果不具备原子性，无法保证全部执行或全不执行，那么就会造成数据库不可信且不可用。
    * MySQL中使用undo log日志实现原子性。
    
* C (Consistency  一致性)
    * 如果一个事务原子地在一个一致地数据库中独立运行，那么在它执行之后，数据库的状态一定是一致的

* I (Isolation  隔离性)
    * 隔离性：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。
    * 事务隔离级别：读未提交、读已提交、可重复读、串行化
    * 事务问题：脏读、不可重复读、幻读

* D (Durability  持久性)
    * 持久性：一旦事务被提交，数据一定会被写入到数据库中并持久存储起来。
    * MySQL使用重做日志（redo log）实现事务的持久性



##### 事务的隔离性
SQL 标准定义了四种隔离级别，MySQL 全都支持。这四种隔离级别分别是：
1. 读未提交（READ UNCOMMITTED）RU ：使用查询语句不会加锁，可能会读到未提交的行
2. 读提交 （READ COMMITTED）RC ：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果
3. 可重复读 （REPEATABLE READ）RR ：多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能发生幻读
4. 串行化 （SERIALIZABLE）：InnoDB 隐式地将全部的查询语句加上共享锁，解决了幻读的问题；

从上往下，隔离强度逐渐增强，性能逐渐变差。采用哪种隔离级别要根据系统需求权衡决定，其中，可重复读是 MySQL 的默认级别。
事务隔离其实就是为了解决上面提到的脏读、不可重复读、幻读这几个问题，下面展示了 4 种隔离级别对这三个问题的解决程度。
![16231405122174](https://github.com/binbinshan/Review-Up/blob/master/images/blog/1623140512217411.jpg)


##### 分布式事务方案

分布式事务实现方案从类型上去分刚性事务、柔型事务。
* 刚性事务：通常无业务改造，强一致性，原生支持回滚/隔离性，低并发，适合短事务。
* 柔性事务：有业务改造，最终一致性，实现补偿接口，实现资源锁定接口，高并发，适合长事务。

刚性事务：XA 协议（2PC、JTA、JTS）、3PC
柔型事务：TCC/FMT、Saga（状态机模式、Aop模式）、本地事务消息、消息事务（半消息）、最多努力通知型事务

1. XA 的全称是 eXtended Architecture，它是一个分布式事务协议，通过二阶段提交协议保证强一致性。
    ![-w861](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257318524388.jpg)


1. TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。TCC 模型完全交由业务实现，每个子业务都需要实现 Try-Confirm-Cancel 三个接口，对业务侵入大，资源锁定交由业务方。
    ![-w1035](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257318795533.jpg)

    
1. Saga : 在Saga模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。
    ![-w1208](https://github.com/binbinshan/Review-Up/blob/master/images/blog/16257320292866.jpg)
    分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。
    Saga模式下分布式事务通常是由事件驱动的，各个参与者之间是异步执行的，Saga 模式是一种长事务解决方案。
    Saga模式所具备的优势有：一阶段提交本地数据库事务，无锁，高性能；参与者可以采用事务驱动异步执行，高吞吐；补偿服务即正向服务的“反向”，易于理解、易于实现；不过，Saga 模式由于一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以不能保证隔离性，需要使用语义锁等方式来保证隔离性。
    

##### 分布式事务框架
这里因为篇幅的原因，就不展开介绍这两个框架了，后续如果有机会，我会对两个框架进行分享
1. Seata
github地址：[seata](https://github.com/seata/seata)
Seata（Simple Extensible Autonomous Transaction Architecture，一站式分布式事务解决方案）是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。Seata 的设计思路是将一个分布式事务可以理解成一个全局事务，下面挂了若干个分支事务，而一个分支事务是一个满足 ACID 的本地事务，因此我们可以操作分布式事务像操作本地事务一样。
    
1. cadence
github地址：[cadence](https://github.com/uber/cadence)
Cadence是一个分布式的、可伸缩的、持久的、高可用的编排引擎，可以以可伸缩的、有弹性的方式执行异步长时间运行的业务逻辑。

### 问题4：单体系统解耦拆分
我们系统是直接以微服务进行开发的，所以这里我也不单独展开了，后续也会有文章分享如何进行单体系统解耦拆分。
    