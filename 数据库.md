# 数据库

   如需要展开全部,可以在网页控制台执行以下代码
   ```
   [...document.getElementById("readme").getElementsByTagName("details")].forEach(e => e.open = true)
   ```

* [MySQL 为什么使用 B+ 树来作索引，对比 B 树它的优点和缺点是什么？](#1)

* [数据库的事务隔离级别有哪些？各有哪些优缺点？](#2)

* [什么是数据库事务，MySQL 为什么会使用 InnoDB 作为默认选项？](#3)

* [简述脏读和幻读的发生场景，InnoDB 是如何解决快照读带来的幻读？](#4)

* [快照读和当前读是什么？InnoDB 是如何解决当前读带来的幻读？](#5)

* [简述 MySQL 的锁？](#6)

* [简述乐观锁以及悲观锁的区别以及使用场景？](#7)

* [什么情况下会发生死锁，如何解决死锁？](#8)

* [聚簇索引和非聚簇索引有什么区别？](#9)

* [唯一索引与普通索引的区别是什么？使用索引会有哪些优缺点？](#10)

* [MySQL 的索引什么情况下会失效？](#11)

* [数据库如何设计索引，如何优化查询？](#12)

* [假设建立联合索引 (a, b, c) 如果对字段 a 和 c 查询，会用到这个联合索引吗？](#13)

* [MySQL 有哪些常见的存储引擎？它们的区别是什么？](#14)

* [什么是 SQL 注入攻击？如何防止这类攻击？](#15)

* [简述 MySQL 的主从同步机制，如果同步失败会怎么样？(未完)](#16)

* [MySQL 有什么调优的方式？(未完)](#17)

* [为什么要使用Redis？能简单介绍下Redis吗？](#18)

* [Redis支持哪些数据类型？](#19)

* [Redis支持数据类型的底层实现？](#20)

* [Redis 如何实现分布式锁？](#21)

* [简述 Redis 中如何防止缓存雪崩和缓存击穿？](#22)

* [redis 的过期策略都有哪些？内存淘汰机制都有哪些？](#23)

* [手写一下 LRU 代码实现？](#24)

* [简述 Redis 持久化中 RDB 以及 AOF 方案的优缺点](#25)

* [如何保证缓存数据库双写一致？](#26)

* [Redis高并发、高可用怎么做的？](#27)

* [假设 Redis 的 master 节点宕机了，你会怎么进行数据恢复？](#28)

Redis 序列化有哪些方式？



------

### <span id="1">1.MySQL 为什么使用 B+ 树来作索引，对比 B 树它的优点和缺点是什么？</span>
<details>
<summary>展开</summary>

##### 数组
如果针对索引的操作只是精确查询或者范围查询的话，那么使用数组就够了，通过二分查找时间复杂度是O(logn)。但是如果还需要插入索引的话，那么因为数组的有序性，就需要O(n)的时间复杂度才能插入。

##### 二叉搜索树
由于数组O(n)的插入复杂度，所以可以考虑使用二叉搜索树，这样查询、插入等操作的时间复杂度就都是O(logn),也就是需要操作 logn次的 I/O 操作取出数据。
但是二叉搜索树有一个问题，就是范围查询很慢，需要不断的从根节点出发，进行搜索，所以可以进行优化数据只保存在叶子节点上，并使用双向链表连接，这样就不用每次都从根节点出发了。

##### B+树
又因为二叉搜索树在数据量大的时候，树的高度太高了，比如高为10的的BST，就需要10次 I/O 操作，所以继续优化的话，就是让树变的矮胖，减少I/O次数，就变成“多叉搜索树”。这个就是B+ Tree.

B Tree 和 B+ Tree都是多叉搜索树，但是两者有以下几个区别：
1. B树的节点即保存数据也保存索引，而B+树只有叶子节点保存索引和数据，其余节点只保存索引。
2. 范围查询：B树进行范围查询的时候，只能通过父节点和子节点进行连接，那么就必须不断回溯，会产生很多I/O操作。而B+ 树因为叶子节点之间通过双向链表连接，可以使用前后指针就可以查出所有数据。
3. B+树的检索效率稳定，任何查找都是从根节点到叶子节点的过程。


</details>

------

### <span id="2">2.数据库的事务隔离级别有哪些？各有哪些优缺点？</span>
<details>
<summary>展开</summary>

事务的隔离级别对应的隔离性，属于数据库事务ACID中的I。

事务隔离级别要解决的问题：
* 脏读：指的是读到了其他事务未提交的数据，未提交代表可能回滚，也就是读到了并一定最终存在的数据。
* 不可重复读：指的是在同一事物中，不同时刻读到的同一批数据可能不一样，受到其他事物的影响，通常针对UPDATE操作。
* 幻读：指的的是在同一事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。通常针对INSERT操作。

MYSQL事物的隔离级别为：
* 读未提交（RU）：可能出现 脏读、不可重复读、幻读
* 读已提交（RC）：可能出现 不可重复读、幻读
* 可重复读（RR）：可能出现 幻读
* 串行化：不会出现 脏读、不可重复读、幻读

事务隔离级别中 读未提交效率最高，因为不涉及加锁，而串行化效率最低，因为所有语句都是串行执行。

</details>


------

### <span id="3">3.什么是数据库事务，MySQL 为什么会使用 InnoDB 作为默认选项？</span>
<details>
<summary>展开</summary>

数据库事务指的 ACID 四大特性，包括以下：
* 原子性：事务就是一系列的操作，要么全部都执行，要么全都不执行。
* 一致性：是指事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。

* 隔离性：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。
* 持久性：一旦事务被提交，数据一定会被写入到数据库中并持久存储起来。

在MySQL中，使用undo log日志实现原子性。使用重做日志（redo log）实现事务的持久性。
Mysql中事务都是指在 InnoDB 引擎下，MyISAM 引擎是不支持事务的。所以默认的引擎是innodb。

 </details>



------

### <span id="4">4.简述脏读和幻读的发生场景，InnoDB 是如何解决快照读带来的幻读？</span>
<details>
<summary>展开</summary>

* 脏读：读到了其他事务未提交的数据，未提交代表可能回滚，也就是读到了并一定最终存在的数据。
* 不可重复读：指的是在同一事物中，不同时刻读到的同一批数据可能不一样，受到其他事物的影响，通常针对UPDATE操作。
* 幻读：指的的是在同一事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。通常针对INSERT操作。


在InnoDB中的事务隔离级别，读已提交解决了脏读，不可重复读解决了脏读、不可重复读、幻读。在MySQL中读已提交和不可重复读的隔离级别都是基于MVCC快照实现的，具体就是采用了基于undo log版本链实现的ReadView机制给事务打快照。

### ReadView实现
ReadView机制就是将当时事务状态记下来，之后的所有读操作根据其事务ID（即trx_id）与快照中的事务的状态作比较，以此判断ReadView对于事务的可见性。

ReadView中保存的事务状态主要包括：
* m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表，也就是有哪些事务在MySQL里执行还没提交的。

* min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值。
* max_trx_id：表示生成ReadView时系统中下一个要生成的事务id。（注意max_trx_id并不是m_ids中的最大值，事务id是递增分配的。假设现在有id为1，2，3这三个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，m_ids就包括1和2，min_trx_id的值就是1，max_trx_id的值就是4。）

* creator_trx_id：表示生成该ReadView的事务的事务id，也就是当前的事务ID。

判断规则：有了这个ReadView，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：
* 如果被访问版本的trx_id = ReadView中的creator_trx_id ，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。

* 如果被访问版本的trx_id < ReadView中的min_trx_id，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。

* 如果被访问版本的trx_id >= ReadView中的max_trx_id，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。

* 如果被访问版本的trx_id在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中。
    * 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；
    * 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

总结上述规则，就是：
1. 当前事务内的更新，可以读到；
2. 版本未提交，不能读到；
3. 版本已提交，但是却在快照创建后提交的，不能读到；
4. 版本已提交，且是在快照创建前提交的，可以读到；

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。


读已提交(RC)实现原理 :每次读取数据前都生成一个ReadView
可重复读(RR)实现原理 :在第一次读取数据时生成一个ReadView
 
</details>



------

### <span id="5">5.快照读和当前读是什么？InnoDB 是如何解决当前读带来的幻读？</span>
<details>
<summary>展开</summary>

快照读：在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，这就是快照读。
当前读：读到的都是数据库最新的数据。

快照读：就是select
* select * from table ….;

当前读：特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁。
* select * from table where ? lock in share mode;
* select * from table where ? for update;
* insert;
* update ;
* delete;

为什么要强调快照读和当前读呢？因为在MySQL官方认为连续的快照读或者连续的当前读出现数据不一致才符合幻读的定义。

快照读：使用MVCC解决幻读。
当前读：使用next-key，结合了索引行锁和间隙锁来解决幻读。

情况1：事务A开启了一个事务后，进行了两次select，这个时候都是使用快照读，那么通过结果我们可以看出确实没有查出修改后的数据，这说明RR级别下，避免了**不可重复读**问题。

| 事务A | 事务B |
| --- | --- |
| BEGIN; | BEGIN; |
| SELECT * from `user`; 结果：id=13 nick_name == ‘aa' |  |
|  | UPDATE `user` set nick_name = 'bb' where id = 13; |
|  | COMMIT; |
| SELECT * from `user`; 结果：id=13 nick_name == ‘aa' |  |
| COMMIT; |  |

情况2：事务A开启了一个事务后，进行了两次select，这个时候都是使用快照读，那么通过结果我们可以看出确实没有查出修改后的数据，这说明InnoDB下RR级别下快照读，避免了**幻读**问题。

| 事务A | 事务B |
| --- | --- |
| BEGIN; | BEGIN; |
| SELECT * from `user`; 结果：id=13 nick_name == ‘aa' |  |
|  | INSERT INTO `user` (`id`,`nick_name`, ) VALUES (15, 'cc', ); |
|  | COMMIT; |
| SELECT * from `user`; 结果：id=13 nick_name == ‘aa' ROW=1 |  |
| COMMIT; |  |

情况3：事务A开启了一个时候后，进行了一次select,进行了一次update,这个时候select使用快照读,而update则使用当前读，那么这种情况（「快照读」和「当前读」一起使用）下就会出现**幻读**。

| 事务A | 事务B |
| --- | --- |
| BEGIN; | BEGIN; |
| SELECT * from `user`; 结果：id=13 nick_name == ‘aa' |  |
|  | INSERT INTO `user` (`id`,`nick_name`, ) VALUES (15, 'cc', ); |
|  | COMMIT; |
|  update `user` set nick_name = 'dd’ ; 结果：Affected rows: 2|  |
| SELECT * from `user`; 结果：id=13 nick_name = ‘aa’ id = 15 nick_name = 15 |  |
| COMMIT; |  |

情况4：针对上面的情况，我们调整下代码，将事务B的插入放在事务UPDATE后面，那么这种情况就没有发生幻读，这是因为当前读加了加 next-key lock，这样事务B就会一直阻塞到事务A提交。

| 事务A | 事务B |
| --- | --- |
| BEGIN; |  |
| SELECT * from `user`; 结果：id=13 nick_name == ‘aa' |  |
| update user set nick_name = 'dd’ ; 结果：Affected rows: 1 |  |
|  | BEGIN; |
|  | INSERT INTO user (id,nick_name, ) VALUES (15, 'cc', ); |
| SELECT * from `user`; 结果：id=13 nick_name = ‘dd’  | Wait  |
| COMMIT; |  |
|  | COMMIT; |

情况5：上面情况说的是当前读加了Next-Key锁，我们也可以自己手动给select加next-key锁，这样也不会出现幻读；

| 事务A | 事务B |
| --- | --- |
| BEGIN; |  |
| SELECT * from `user` for update; 结果：id=13 nick_name == ‘aa' |  |
|  | BEGIN; |
|  | INSERT INTO user (id,nick_name, ) VALUES (15, 'cc', );  |
| SELECT * from `user`; 结果：id=13 nick_name = ‘aa’  | Wait |
| COMMIT; |  |
|  | COMMIT; |

总结一下：快照读的时候无需任何操作即可避免幻读，当快照读和当前读混合使用的使用就需要按照实际情况显式加锁去解决幻读或者按照规范使用next-key来解决。




</details>



------

### <span id="6">6.简述 MySQL 的锁？</span>
<details>
<summary>展开</summary>


InnoDB中关于锁的种类分为两类：
1. 共享锁（Shared Lock）S：读锁
2. 互斥锁（Exclusive Lock）X：写锁

![](https://github.com/binbinshan/Review-Up/blob/master/images/数据库/16246107884819.jpg)

共享锁代表了读操作、互斥锁代表了写操作，所以我们可以在数据库中并行读，但是只能串行写，只有这样才能保证不会发生线程竞争，实现线程安全。


共享锁还是互斥锁其实都只是对某一个数据行进行加锁，InnoDB 支持多种粒度的锁，也就是行锁和表锁；为了支持多粒度锁定，InnoDB 存储引擎引入了意向锁（Intention Lock），意向锁就是一种表级锁。
* 意向共享锁：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁；
* 意向互斥锁：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁；

如果没有意向锁，当已经使用行锁对表中的某一行进行加锁，如果另外一个请求要对全表进行修改，那么就需要对所有的行是否被锁定进行扫描，在这种情况下，效率是非常低的；
在引入意向锁之后，当使用行锁对表中的某一行进行修改之前，会先为表添加意向互斥锁（IX），再为行记录添加互斥锁（X），在这时如果有别的事务尝试对全表进行修改就不需要判断表中的每一行数据是否被加锁了，只需要通过等待意向互斥锁被释放就可以了。


### 锁的算法
在MySQL中，有三种锁的实现：
1. Record Lock：记录锁，是加到索引记录上的锁。当通过聚簇索引或二级索引查找时，会在索引上加Record Lock，如果不是索引的话，就会给整张表加锁。
2. Gap Lock：间隙锁，是索引记录之间上的锁。间隙锁是性能与并发的部分折中，并只适用于一些事务隔离级别。例如，SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE; 就会阻止其他事务插入 c1 = 15 的记录

3. Next-Key Lock：下一键锁，是记录锁和记录前的间隙锁的结合，是一个索引记录锁加上一个在索引记录之前的间隙上的间隙锁。

    ```
    +------|-------------|--------------|-------+
    |   id | last_name   | first_name   |   age |
    |------|-------------|--------------|-------|
    |    4 | stark       | tony         |    21 |
    |    1 | tom         | hiddleston   |    30 |
    |    3 | morgan      | freeman      |    40 |
    |    5 | jeff        | dean         |    50 |
    |    2 | donald      | trump        |    80 |
    +------|-------------|--------------|-------+
    
    如果使用 Next-Key 锁，那么 Next-Key 锁就可以在需要的时候锁定以下的范围：
    (-∞, 21]
    (21, 30]
    (30, 40]
    (40, 50]
    (50, 80]
    (80, ∞)
    
    Next-Key 锁锁定的是当前值和前面的范围。
    ```


    比如 SELECT * FROM users WHERE age = 30 FOR UPDATE; InnoDB 不仅会在范围 (21, 30] 上加 Next-Key 锁，还会在这条记录后面的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定。


</details>


------

### <span id="7">7.简述乐观锁以及悲观锁的区别以及使用场景？</span>
<details>
<summary>展开</summary>

锁的种类一般分为乐观锁和悲观锁，而在innoDB中使用的就是悲观锁。而按照锁的粒度划分，也可以分成行锁和表锁。

乐观锁和悲观锁其实都是并发控制的机制，同时它们在原理上就有着本质的差别；
* 乐观锁是一种思想，它其实并不是一种真正的『锁』，它会先尝试对资源进行修改，在写回时判断资源是否进行了改变，如果没有发生改变就会写回，否则就会进行重试，在整个的执行过程中其实都没有对数据库进行加锁；

* 悲观锁就是一种真正的锁了，它会在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源；

乐观锁不会存在死锁的问题，但是由于更新后验证，所以当冲突频率和重试成本较高时更推荐使用悲观锁，而需要非常高的响应速度并且并发量非常大的时候使用乐观锁就能较好的解决问题。

</details>


------

### <span id="8">8.什么情况下会发生死锁，如何解决死锁？</span>
<details>
<summary>展开</summary>


A事务中：
```
//加了 s 锁
SELECT * FROM t WHERE i = 1 FOR SHARE;
```
B事务中：
```
//会加上 x 锁
DELETE FROM t WHERE i = 1;
```
此时B事务会等待A事务提交，因为s锁和x锁是互斥的。

A事务中又执行了：
```
DELETE FROM t WHERE i = 1;
//此时会返回错误信息：
Deadlock found when trying to get lock; 试图锁定时发现死锁;
```

A先加了共享锁，B加了排他锁，A又加了排他锁。

##### 死锁检测
死锁检测是一个MySQL Server层的自动检测机制，可以及时发现两个或者多个session间互斥资源的申请造成的死锁，且会自动回滚一个（或多个）事物代价相对较小的session，让执行代价最大的先执行。该参数默认就是打开的。

如果关闭了死锁检测机制，会根据innodb_lock_wait_timeout，该参数指定了“锁申请时候的最长等待时间”，当发生锁等待超时时，回滚当前语句 （不是整个事务）。

##### 死锁优化
1. 减少代码层面并发
2. 减少大事务的出现
3. 减少锁时间长的在事务前面


</details>



------

### <span id="9">9.聚簇索引和非聚簇索引有什么区别？</span>
<details>
<summary>展开</summary>

聚簇索引：
    Innodb引擎要求每张表都要有主键，然后会根据这个主键创建一个默认索引，这个索引中叶子节点的值就是主键key所在行的数据(数据和索引是一个文件)。当没有指定主键的时候，Mysql会默认生成一个隐藏的主键。


非聚簇索引：
    是指对某个非主键的字段创建索引，该索引中叶子结点存的值就是主键的值，需要根据主键再去聚簇索引中根据key查询到数据。

当使用非聚簇索引进行查询的时候，会先找到其叶子节点存储的主键值，然后再根据主键聚簇索引查询。整个过程称为回表。
当然回表也不是绝对的，当查询的值已经被非聚簇索引全部包含(覆盖索引)，这个时候直接返回非聚簇索引即可(key)。

</details>


------

### <span id="10">10.唯一索引与普通索引的区别是什么？使用索引会有哪些优缺点？</span>
<details>
<summary>展开</summary>


普通索引：
    比如查找 k = 5 的数据，查找到满足条件的第一个记录5后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。

唯一索引：
    由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

上面的查询区别对于性能而言是微乎其微的，InnoDB读写数据是按**数据页**来的，也是说当找到k=5的记录的时候，它所在的数据⻚就都在内存里了，那么我们只需要判断下一条数据是不是等于5即可，直到出现不为5的值为止，这些都是在内存中操作的，所以性能微乎其微。

</details>



------

### <span id="11">11.MySQL 的索引什么情况下会失效？</span>
<details>
<summary>展开</summary>

1. where 子句中对字段进行 null 值判断 。
2. where 子句中使用 != 或 <> 操作符 。
3. where 中使用 in 和 not in 。
4. 不符合最左前缀匹配原则 。

</details>

------

### <span id="12">12.数据库如何设计索引，如何优化查询？</span>
<details>
<summary>展开</summary>

1. 可以设计一个或者两三个联合索引，尽量保证 where、order by、group by后续跟的字段都是联合索引的最左侧开始的部分字段，这样就都能用上索引。
2. 选择基数比较大的字段，就是值比较多的字段，这样才能发挥出B+树快速二分查找的优势。
3. 选择字段的类型比较小的字段，这样可以减少树的磁盘大小。
4. 索引不要设计太多，2、3个联合索引覆盖全部查询即可。
5. 主键一定是自增的，别用UUID之类的，因为会导致频繁的页分裂和挪动。

</details>

------

### <span id="13">13.假设建立联合索引 (a, b, c) 如果对字段 a 和 c 查询，会用到这个联合索引吗？</span>
<details>
<summary>展开</summary>

select * from table where a='' and c=''  //a会先走索引过滤掉一部分数据，c不走索引。

</details>


------

### <span id="14">14.MySQL 有哪些常见的存储引擎？它们的区别是什么？</span>
<details>
<summary>展开</summary>

mysql支持的存储引擎有很多种,比如MyISAM、InnoDB,目前国内基本上都是使用InnoDB,而且这个也是mysql 5.5之后的默认存储引擎。

## InnoDB
为什么都会使用InnoDB呢?
主要是InnoDB生态好，它支持**事务，走聚簇索引，强制主键，支持外键**，另外针对高可用可以做**主备切换**，针对高并发可以做读写分离，针对大数据量可以做分库分表。

## MyIasm
MyIasm主要是不支持事务，不支持外键约束，索引和数据文件分开，所以内存里可以放更多的缓存，对查询的性能会更好，适用少量插入，大量查询的场景。
</details>


------

### <span id="15">15.什么是 SQL 注入攻击？如何防止这类攻击？</span>
<details>
<summary>展开</summary>

SQL注入攻击，是指在界面的表单信息或URL上输入一些奇怪的SQL片段（例如“or ‘1’=’1’”这样的语句），有可能入侵参数检验不足的应用程序。

sql注入可以使用预编译的sql语句来解决，预编译的语句类似如下：
```
//参数会在SQL语句中用占位符”?”来标识，然后使用prepareStatement来预编译这个SQL语句。
String selectPerson = "SELECT * FROM PERSON WHERE ID=?";
PreparedStatement ps = conn.prepareStatement(selectPerson);
ps.setInt(1,id);
```

在MyBatis中支持两种参数符号，一种是#，另一种是$。
1. 使用参数符号#，MyBatis会创建一个预编译语句，参数会在SQL语句中用占位符”?”来标识，然后使用prepareStatement来预编译这个SQL语句。

2. 使用参数符号$时，MyBatis直接用字符串拼接把参数和SQL语句拼接在一起，然后执行。这种情况非常危险，极容易产生SQL注入漏洞。

like参数注入。使用如下SQL语句可防止SQL注入：like concat('%',#{title}, '%')，
</details>




------

### <span id="16">16.简述 MySQL 的主从同步机制，如果同步失败会怎么样？</span>
<details>
<summary>展开</summary>

</details>

------

### <span id="17">17.MySQL 有什么调优的方式？</span>
<details>
<summary>展开</summary>

</details>



------

### <span id="18">18.为什么要使用Redis？能简单介绍下Redis吗？</span>
<details>
<summary>展开</summary>
Redis是基于内存的KV数据结构存储，用作数据库、缓存和消息代理。

我们开发的系统中，主要是把用户信息放入缓存中，如用户信息、部门信息等经常不变的数据放入Redis中。

使用Redis的两个主要原因：

* 高并发：在高并发的情况下，一秒进入5000个请求，mysql最多也就每秒2000qbs，这个时候5000个请求就会把mysql干崩溃，所以要使用缓存来保证高并发场景。
* 高性能：比如一个查询接口，查询一大堆数据，耗时将近500ms，这个时候就可以把查询的结果放入到redis中，下次查询通过Key去查找，只需要20ms。

</details>


------

### <span id="19">19.Redis支持哪些数据类型？</span>
<details>
<summary>展开</summary>

![](https://github.com/binbinshan/Review-Up/blob/master/images/数据库/Redis数据结构.png)

</details>


------

### <span id="20">20.Redis支持数据类型的底层实现？</span>
<details>
<summary>展开</summary>

![](https://github.com/binbinshan/Review-Up/blob/master/images/数据库/Redis数据结构和对象.png)


</details>


------

### <span id="21">21.Redis 如何实现分布式锁？</span>
<details>
<summary>展开</summary>

> 分布式锁和我们平常讲到的锁原理基本一样，目的就是确保在多个线程并发时，只有一个线程在同一刻操作这个业务或者说方法、变量。
在一个进程中，也就是一个jvm或者说应用中，我们很容易去处理控制，在jdk java.util并发包中已经为我们提供了这些方法去加锁，比如synchronized关键字或者Lock锁，都可以处理。
在高并发的场景下，我们需要部署多台服务器同时去处理业务，那么这些机器要同时去处理这个业务（例如秒杀)，分布式锁可以把整个集群就当作是一个应用一样去处理。

> 分布式锁的实现方式：Redis、Zookeeper等

### Redis

Redis有3种部署方式：
* 单机Redis模式
* master-slave + sentinel模式
* redis cluster模式

##### 单机Redis模式下实现分布式锁
使用Redis的 SetNX 来实现，其原理就是判断对应的Key是否存在，存在即代表被锁定，不存在代表可以进行加锁。

注意点：
1. 必须考虑锁无法释放的情况，添加过期时间。
2. 必须原子性的获得锁和设置锁过期时间。
3. 必须判断是否自己的锁(通过Value)，避免释放了别人的锁。
4. 必须使用lua脚本保证 判断是否自己的锁 和 解锁 的原子性。

##### 集群Redis模式下实现分布式锁
Redis 做分布式锁的缺点在于：
1. 采用单机部署模式，会存在单点故障。
2. 采用 master-slave 模式，加锁的时候只对Master加锁，但是如果 master 节点故障了，发生主从切换，此时就会有可能出现锁丢失的问题。

基于上述问题，Redis官方提出了RedLock算法，算法大概如下：
> 假设 redis 的部署模式是 redis cluster，总共有 5 个 master 节点，通过以下步骤获取一把锁：
> * 获取当前时间戳，单位是毫秒
> * 依次尝试在每个 master 节点上创建锁，创建锁的时间会设置较短。如果创建锁的时间内无法获取锁，就会放弃获取这个锁，进而尝试获取下个锁。
> * 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点（n / 2 +1）。
> * 客户端计算建立好锁的时间(创建锁的时间)，如果建立锁的时间小于超时时间，就算建立成功了，key 的真正有效时间等于有效时间TTL 减去获取锁所使用的时间。
> * 要是锁建立失败了，那么就依次删除这个锁，客户端应该在所有的 Redis 实例上进行解锁。

通过RedLock就可以解决 Master-Slave模式下，节点挂掉，由于异步通信，导致锁失效的问题。

* 这里还有一个问题就是故障重启后的情况：

> 一共有 A、B、C 这三个节点。
> 客户端 1 在 A，B 上加锁成功。C 上加锁失败。
> 这时节点 B 崩溃重启了，但是由于持久化策略导致客户端 1 在 B 上的锁没有持久化下来。
> 客户端 2 发起申请同一把锁的操作，在 B，C 上加锁成功。
> 这个时候就又出现同一把锁，同时被客户端 1 和客户端 2 所持有了。

Redis 的 AOF 持久化方式默认情况下是每秒写一次磁盘，即 fsync 操作，因此最坏的情况下可能丢失 1 秒的数据。所以由于节点重启引发的锁失效问题，总是有可能出现的。

解决方案：一个节点崩溃后，不要立即重启它，而是等待一定的时间后再重启。等待的时间应该大于锁的过期时间（TTL）。这样做的目的是保证这个节点在重启前所参与的锁都过期。相当于把以前的帐勾销之后才能参与后面的加锁操作。
缺点是在等待的时间内，这个节点是不对外工作的。那么如果大多数节点都挂了，进入了等待。就会导致系统的不可用，因为系统在TTL时间内任何锁都将无法加锁成功。

Redlock 算法还有一个需要注意的点是它的释放锁操作。释放锁的时候是要向所有节点发起释放锁的操作的。


在开源框架Redisson中实现了RedLock，并且使用看门狗确保锁过期时间大于业务执行时间的问题。
代码如下：

![](https://github.com/binbinshan/Review-Up/blob/master/images/数据库/16251327425869.jpg)

</details>



------

### <span id="22">22.简述 Redis 中如何防止缓存雪崩和缓存击穿？</span>
<details>
<summary>展开</summary>


## 缓存雪崩
* 假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机或者大面积失效了。此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，然后就挂掉了，导致服务不可用。

* 解决方案，主要从三个方面：
    1. 发生雪崩前，让Redis高可用，比如主从+哨兵、redis集群模式，数据库层面分库分表、读写分离等。失效时间上加上一个随机值，避免大面积缓存失效。
    2. 发生雪崩时，使用 hystrix 限流&降级 ，当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上
    3. 发生雪崩后，一定要持久化，支持恢复

## 缓存击穿
* 缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。

* 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。


## 缓存穿透
* 假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。
例如，数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。

* 解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。
* 或者使用布隆过滤器，在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询 key 是否存在，如果不存在就直接返回。

</details>



------

### <span id="23">23.redis 的过期策略都有哪些？内存淘汰机制都有哪些？</span>
<details>
<summary>展开</summary>

Redis都是存储在内存上的，假设我们内存是10G，你放入了20G的数据到Redis里，那肯定会有10G的数据丢失，那么怎么判断丢弃哪10G呢？这就需要Redis的过期策略。

### Redis的过期策略
redis 过期策略是：定期删除+惰性删除。
* 定期删除：
    * 指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。
    * 这里Redis肯定不能扫描全部的key进行判断，否则CPU消耗很大，实际上 redis 是每隔 100ms 随机抽取一些 key 来检查和删除的。

* 惰性删除：
    * 定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删除了。
    * 惰性删除就是获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。

### 内存淘汰机制都有哪些？
在极端情况下，定期删除漏掉了很多过期 key，然后也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽了。这个时候就需要内存淘汰机制。

redis 内存淘汰机制有以下8个选项：
* noeviction：不会驱逐任何key
* volatile-ttl：删除马上要过期的key
* volatile-lfu：对所有设置了过期时间的key使用LFU算法进行删除
* allkeys-lfu：对所有key使用LFU算法进行删除
* volatile-lru：对所有设置了过期时间的key使用LRU算法进行删除
* allkeys-lru：对所有key使用LRU算法进行删除
* volatile-random：对所有设置了过期时间的key随机删除
* allkeys-random：对所有key随机删除

2个维度：过期键中筛选、所有键中筛选
4个方面：LRU(最近最少)、LFU(最少频率)、random、ttl（Time To Live）


LRU，最近最少使用，把数据加入一个链表中，按访问时间排序，发生淘汰的时候，把访问时间最旧的淘汰掉。
LFU，最近不经常使用，把数据加入到链表中，按频次排序，一个数据被访问过，把它的频次+1，发生淘汰的时候，把频次低的淘汰掉。

上面的淘汰机制很多，常用的就是allkeys-lru，也就是内存不够写入新数据时，就把**最近最少**使用的key给干掉。

</details>


------

### <span id="24">24.手写一下 LRU 代码实现？</span>
<details>
<summary>展开</summary>


</details>



------


### <span id="25">25.简述 Redis 持久化中 RDB 以及 AOF 方案的优缺点？</span>
<details>
<summary>展开</summary>

持久化的目的是做数据灾备，恢复数据，也是高可用的一环。即使我们的Redis挂了，也能迅速重启后，通过备份数据快速恢复。Redis提供的持久化机制共两种RDB和AOF。

### RDB

RDB机制：即快照机制，它将某个时间点的所有Redis数据保存到一个经过压缩的二进制文件(RDB)中，该文件可以被还原为数据库状态。RDB文件是在服务器重启时进行自动载入的。

> 备份方式：
* SAVE：SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止
* BGSAVE：BGSAVE会fork()子线程，负责创建RDB文件。

> 使用方式：
1. 主动触发：手动在命令行执行SAVE、BGSAVE；
2. 被动触发：通过下列配置，可以自动触发BGSAVE备份RDB文件。

    ```
    save 900 1            900秒内执行一次set操作 则持久化1次  
    save 300 10           300秒内执行10次set操作,则持久化1次
    save 60 10000         60秒内执行10000次set操作,则持久化1次
    ```

> 工作流程：
1. SAVE使用主线程，BGSAVE使用子线程，将数据集写入临时RDB文件中。
2. 当完成写入后，使用新的RDB文件替换旧的RDB文件。

> 优点：
1. RDB文件内容非常紧凑，适合冷备。
2. 恢复大数据量时，RDB比AOF更快

> 缺点：
1. 如果发生故障，会丢失最后一次创建快照之后的数据。
2. 如果大数据量时，备份时间会很长。

### AOF
RDB持久化记录的是数据库本身，而AOF(Append Only File)则记录Redis服务器所执行的写命令。然后通过 aof 内存缓冲区，特定的时间下刷新缓冲区到磁盘文件中，也就是我们的 aof 文件。

> 配置：
1. appendonly 指定 redis 是否启用 AOF 持久化策略
2. appendfilename 指明生成的 AOF 文件名称。

> 工作流程：
* 创建AOF：
    1. 执行Redis写入命令。
    2. 追加到AOF缓冲区的结尾。
    3. 按照配置的**同步磁盘策略**同步到磁盘上。
* 重写AOF

* 载入AOF：
    * 服务器只要读入并重新执行一遍AOF文件里面保存的写命令，就可以还原服务器关闭之前的数据库状态。

> 同步磁盘策略：
1. always：每一次增加命令，就刷新一次缓存区。
2. everysec：每秒执行一次磁盘写入，期间所有的命令都会存储在 aof 缓存区。（默认配置）
3. no：不做控制，任由操作系统决定什么时候刷新缓冲区。


> 重写AOF：

随着时间的增长，AOF文件的大小将会越来越大。为了解决这个问题，Redis提供了AOF重写功能。重写后，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件。
重写策略：首先从数据库中读取键现在的值，然后用一条命令去记录键值对，用到了aof_rewrite函数。
例如：
```
set a "a"
set b "b"
set c "c"
del a
del b
```
正常情况下，aof 文件中会保存着五条命令的 log，然后数据恢复的时候依次执行即可。而当启动 AOF 重写后，实际上我们的 aof 文件中只有 set c "c" 这一条命令的 log。
因为aof_rewrite函数包含了大量写入操作，调用时会导致线程被长时间阻塞，所以Redis将AOF重写放入子进程里。

##### 重写问题

子进程AOF重写时，主进程也在写命令，导致两者状态不一致。
因此，Redis服务器设置了一个AOF重写缓冲区，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。

> 子进程执行AOF期间，服务器进程需要：
1. 执行客户端指令
2. 将执行后的命令追加到AOF缓冲区
3. 将执行后的命令追加到AOF重写缓冲区
4. 子进程执行完AOF后，向父进程发送一个信号。

> 父进程接收后：
1. 将AOF重写缓冲区的内容写入AOF文件中，保证一致性。
2. 对新AOF文件改名，原子的(atomic)覆盖现有AOF文件。
3. 在整个AOF后台重写过程中，只有信号处理函数执行时会对服务器进程（父进程）造成阻塞，在其他时候，AOF后台重写都不会阻塞父进程，这将AOF重写对服务器性能造成的影响降到了最低。


> 优点：
1. AOF 数据可靠性更强，最多丢失一秒数据。
2. AOF 文件是可读的。

> 缺点：
1. AOF 文件通常较大且恢复效率比不上 RDB，不适合做数据冷备份



### 选择RDB还是AOF:
如果同时使用RDB和AOF，redis是默认使用AOF进行数据恢复的，因为AOF的数据更完整。

1. 不要仅仅使用RDB，因为那样会导致丢失很多数据。

2. 也不要仅仅使用AOF，因为有两个问题：
    * 通过AOF做冷备，没有RDB做冷备恢复速度更快;
    * RDB每次生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug。

3. 综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复
</details>

