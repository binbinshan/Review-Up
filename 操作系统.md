# 操作系统

   如需要展开全部,可以在网页控制台执行以下代码
   ```
   [...document.getElementsByTagName("details")].forEach(e => e.open = true)
   ```

* [简述 Linux 内核态与用户态，什么时候会进入内核态？](#1)

* [什么是文件描述符？](#2)

* [简述 Linux 的 I/O模型？](#3)

* [简述 select, poll, epoll 的使用场景以及区别，epoll 中水平触发以及边缘触发有什么不同？](#4)

* [简述 Linux 零拷贝的原理？](#5)

* [Linux 中虚拟内存和物理内存有什么区别？有什么优点？](#6)

* [操作系统如何申请以及管理内存的？](#7)

* [简述操作系统中的缺页中断？](#8)
------

### <span id="1">1.简述 Linux 内核态与用户态，什么时候会进入内核态？</span>
回答这道题的前提，需要先了解几个概念：虚拟地址空间和寻址、 内核空间和用户空间、内核态和用户态。
##### 虚拟地址空间和寻址
<details>
<summary>展开</summary>
以32位操作系统为例，它的寻址空间就是4G(2^32)。

寻址是指操作系统能找到的地址范围，32位的操作系统能找到的最大地址空间就是4G。
操作系统会给每个进程分配4G的虚拟内存空间，这个虚拟内存空间和真实内存空间之间有映射关系。
</details>

##### 内核空间和用户空间
<details>
<summary>展开</summary>
现代操作系统都会有内核，内核可以访问受保护的内存空间和访问底层硬件的权限，所以为了保证内核空间的安全。就需要区分内核空间和用户空间。
所以以4G的地址空间为例，内核空间拥有最上面的 1G 空间，用户空间拥有其余的3G空间。最高 1G 的内核空间是被所有进程共享的。

![](https://github.com/binbinshan/Review-Up/blob/master/images/网络协议/16239276614333.jpg)

也就是每个进程的 4G 地址空间中，最高 1G 都是一样的，即内核空间。只有剩余的 3G 才归进程自己使用。 
</details>

##### 内核态和用户态
<details>
<summary>展开</summary>
在理解了内核空间和用户空间之后，内核态和用户态就非常简单了。当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。

* 在内核态中，进程运行在内核空间中，此时CPU可以执行任何指令，运行代码也不受限制，可以访问任意内存空间。
* 在用户态中，进程运行在用户空间中，此时要受制CPU的各种限制，也只能访问用户态下可访问的虚拟空间地址。
</details>

##### 用户态怎么陷入内核态？
<details>
<summary>展开</summary>
主要是三个方面，会使用户态陷入内核态：

1. 系统调用：用户态进程通过系统调用申请使用操作系统提供的服务来完成任务，比如说读取磁盘上的一个文件，就会将用户态进程转为内核态。

2. 异常：当进程在用户态的执行过程中出现异常，此时就会由当前进程切换到内核中处理异常的服务中，也会将用户态进程转为内核态。
3. 外围设备中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，比如说读取磁盘文件完成，系统会切换到中断处理后的后续操作，这个时候如果执行指令的进程处于用户态时，也会先切入到内核态。
</details>


------

### <span id="2">2.什么是文件描述符？</span>
<details>
<summary>展开</summary>

文件描述符是一个非负整数，从0开始。进程使用文件描述符来标识一个打开的文件。

系统为每个进程维护了一个文件描述符表，表示该进程打开文件的记录表，而**文件描述符**实际上就是这张表的索引。当进程打开（open）或者新建（create）文件时，内核会在该进程的文件列表中新增一个表项，同时返回一个文件描述符 —— 也就是新增表项的下标。

一般来说，每个进程最多可以打开 64 个文件，fd ∈ 0~63。在不同系统上，最多允许打开的文件个数不同，Linux 2.4.22 强制规定最多不能超过 1,048,576。

每个进程默认都有 3 个文件描述符：0 (stdin)、1 (stdout)、2 (stderr)。分别代表：标准输入流、标准输出流、标准错误流。

##### socket和fd

socket 是 Unix 中的术语。socket 可以用于同一台主机的不同进程间的通信，也可以用于不同主机间的通信。一个 socket 包含地址、类型和通信协议等信息，通过 socket() 函数创建。

比如可以将 socket 和 fd 视为同义词，当我们获取了一个socket,返回的就是这个 socket 对应的文件描述符 fd。操作系统将 socket 映射到进程的一个文件描述符上，进程就可以通过读写这个文件描述符来和远程主机通信。

socket 是进程间通信规则的高层抽象，而 fd 提供的是底层的具体实现。socket 与 fd 是一一对应的。通过 socket 通信，实际上就是通过文件描述符 fd 读写文件。这也符合 Unix“一切皆文件”的哲学。

</details>


------

### <span id="3">3.简述 Linux 的 I/O模型</span>
<details>
<summary>展开</summary>

网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。

对于一次IO的read来说分为两步：
1. 等待数据准备
2. 将数据从内核拷贝到进程

对于socket流而言：
1. 通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。
2. 把数据从内核缓冲区复制到应用进程缓冲区。

----
网络IO模型有以下几种：阻塞IO、非阻塞IO、多路复用IO、信号驱动IO、异步IO

* 阻塞IO：socket默认IO模型，进程从用户调用到系统调用，再到读取数据，所有中间过程中进程都是阻塞的，直到数据读取完毕。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16240019257667.jpg)
优点：能够无延迟的返回数据，即处理完即可返回。
缺点：进程会阻塞，导致性能变低。


* 非阻塞IO：应用进程执行系统调用之后，内核会返回一个错误码。应用进程不阻塞可以继续执行，但是需要不断的执行系统调用来获知是否完成，这种方式称为轮询(polling)。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16240025876184.jpg)
优点：进程在等待的时候，可以进行其他任务。
缺点：因为轮询的原因，任务的响应延迟会增大。

* 多路复用IO：使用 select、poll、epoll函数 让多个进程阻塞在这里，当任意一个数据准备好之后，返回进行可读，然后进程再进行系统调用，将数据由内核拷贝到用户进程。

多路复用IO相对于非阻塞IO：前者可以等待多个socket，能实现同时对多个IO端口进行监听。后者只能对一个进程进行轮询。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16240046660747.jpg)
优点：系统开销小，系统不需要创建新的额外进程或者线程
缺点：
前三种IO模型，从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型。都是进程主动等待且向内核检查状态。
高并发的程序一般使用 同步非阻塞 方式而非 多线程 + 同步阻塞方式

* 信号驱动IO：首先允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16240063938595.jpg)

* 异步非阻塞IO：用户进程进行系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16240064759583.jpg)


五种IO比较：

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16240065655489.jpg)

非阻塞IO和异步IO的区别：
非阻塞IO是同步的，而异步IO是异步的，这是因为非阻塞IO要不断的去轮询检查是否数据读取完成，而异步IO会在数据读完之后直接从内核拷贝到用户空间。

</details>


------

### <span id="4">4.简述 select, poll, epoll 的使用场景以及区别，epoll 中水平触发以及边缘触发有什么不同？</span>
<details>
<summary>展开</summary>
select、poll、epoll都是I/O多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个文件描述符，一旦某个描述符就绪（读就绪或写就绪），能够通知程序进行相应的读写操作 。

### select 
使用fd_set(文件描述符集合)，将感兴趣的文件描述符传给select，select会将就绪的文件描述符返回。通知进行读写。

缺点：
1. 用户态和内核态的频繁切换：当需要select监听一个文件描述符时，就会把fd_set从用户态拷贝到内核态。
2. 内核需要遍历传进来的每一个文件描述符，不管是否就绪。
3. 监听的文件描述符数量受限制，最多1024个，不同操作系统可能不同。

### poll
poll 和 select 几乎没有区别。poll 采用链表的方式存储文件描述符，没有最大存储数量的限制。

缺点和select基本一样，除了文件描述符数量不受限制。

### epoll

epoll 是对 select 和 poll 的改进，避免了“性能开销大”和“文件描述符数量少”两个缺点。

* 如何解决性能开销大？
    1. 为每个文件描述符指定了回调函数，并在就绪时将其加入到就绪列表。通过判断就绪列表是否有值，这样时间复杂度就变成了O(1)，select和poll的需要遍历所有的文件描述符集合，时间复杂度是O(n)

    2. 每次调用 select 时都需要向内核拷贝所有要监听的描述符集合，而 epoll 对于每个描述符，只需要在传递一次，之后不需要再次传递。这也大大提高了效率。

* 如何解决文件描述符少？
epoll解决文件描述符数量少的问题，是采用红黑树来存储文件描述符集合。


### 使用场景：
* select ： 更加适用于实时要求更高的场景，因为超时时间可以到纳秒，epoll和poll是到毫秒。
 
* poll ：没有最大描述符数量的限制，如果对实时性要求不高，应该使用 poll 而不是 select，并且如果同时监控小于 1000 个描述符，就没有必要使用 epoll。
 
* epoll 如果只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。

### 水平触发和边缘触发
select，poll 只支持水平触发，epoll 支持水平触发和边缘触发。

水平触发（LT，Level Trigger）：当文件描述符就绪时，会触发通知，如果用户程序没有一次性把数据读/写完，下次还会发出可读/可写信号进行通知。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。

边缘触发（ET，Edge Trigger）：仅当描述符从未就绪变为就绪时，通知一次，之后不会再通知。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。


</details>


------

### <span id="5">5.简述 Linux 零拷贝的原理？</span>
<details>
<summary>展开</summary>

# 简述 Linux 零拷贝的原理

零拷贝技术是指在执行时，避免从一个内存区域复制到另一个内存区域，减少上下文切换和复制的时间。
零拷贝技术带来的改变：
1. 可有效减少从内核态和用户态的上下文切换带来的cpu开销。
2. 减少内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。

在linux中零拷贝的实现主要有三种方式：
1. 用户态直接IO
    应用系统直接访问存储介质，直接将硬件上的数据拷贝到用户空间，避免了内核空间到用户空间的复制，但是还是存在内核空间和用户空间的上下文切换。
    
1. 减少拷贝次数
    在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。

3. 写时复制技术
    写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。


这里主要举一个减少拷贝次数的实现，因为减少拷贝次数是现在的主流实现，通过 mmap + write 实现的零拷贝技术。
### mmap
在传统IO方式，底层实际上通过调用read()和write()来实现，通过read()把数据从硬盘读取到内核缓冲区，再复制到用户缓冲区；然后再通过write()写入到socket缓冲区，最后写入网卡设备。整个过程发生了4次用户态和内核态的上下文切换和4次拷贝。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/2021-06-18_20-04-17.png)


mmap 是 Linux 提供的一种内存映射文件方法，即将将读缓冲区的地址和用户缓冲区的地址进行映射。
简单来说就是使用mmap替换了传统IO中的read+write中的read操作，减少了一次CPU的拷贝。整个过程发生了4次用户态和内核态的上下文切换和3次拷贝。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/2021-06-18_20-07-32.png)
mmap的方式节省了一次CPU拷贝，同时由于用户进程中的内存是虚拟的，只是映射到内核的读缓冲区，所以可以节省一半的内存空间，比较适合大文件的传输。

### Java NIO 零拷贝
在 Java NIO 中的通道（Channel）就相当于操作系统的内核空间（kernel space）的缓冲区，而缓冲区（Buffer）对应的相当于操作系统的用户空间（user space）中的用户缓冲区（user buffer）。 
* 通道（Channel）是全双工的（双向传输），它既可能是读缓冲区（read buffer），也可能是网络缓冲区（socket buffer）。 
* 缓冲区（Buffer）分为堆内存（HeapBuffer）和堆外内存（DirectBuffer），这是通过 malloc() 分配出来的用户态内存。


在Java NIO中通过FileChannel来提供零拷贝的支持，分别是
1. FileChannel.map: 将文件的一部分映射到内存
2. FileChannel.transferTo: 将本Channel的文件字节转移到指定的可写Channel


另外在Netty和RocketMQ中都大量使用了零拷贝技术。


</details>



------

### <span id="6">6.Linux 中虚拟内存和物理内存有什么区别？有什么优点？</span>
<details>
<summary>展开</summary>

### 什么是物理内存？
物理内存也就是内存条，在早期，进程直接通过物理地址操作物理内存，这样也会带来问题：
1. 程序操作相同地址空间会造成互相影响甚至崩溃，而且安全性也得不到保证；
2. 程序运行时，都需要分配空闲区域，而空闲位置不确定，会带来一些重定位问题；

### 什么是虚拟内存？
为了解决物理内存带来的问题，虚拟内存是操作系统物理内存和进程之间的中间层，它为进程隐藏了物理内存这一概念。提供了更简单了访问和操作。
所以虚拟内存的优点就很明显了：
1. 虚拟内存可以为进程提供独立的内存空间
2. 虚拟内存可以控制进程对物理内存的访问

### 物理内存和虚拟内存映射
操作系统是以页的单位来管理内存的，当cpu通过虚拟内存地址寻址时，会通过内存管理单元（MMU）硬件把虚拟内存地址映射为物理内存地址，另外操作系统也会把虚拟地址和物理地址的映射关系维护在页表之中。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16241149210542.jpg)

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16241148587012.jpg)

</details>


------

### <span id="7">7.操作系统如何申请以及管理内存的？</span>
<details>
<summary>展开</summary>

虚拟内存可以为正在运行的进程提供独立的内存空间，制造一种每个进程的内存都是独立的假象。在32位的操作系统中，每个进程会拥有4G的内存空间，其中1G是内核共享空间，其余3G是用户空间使用，
在64位操作系统中，每个进程会拥有256TiB内存空间，内核空间和用户空间分别占 128 TiB。

### 映射
虚拟内存作为操作系统中的逻辑结构，最终进程还是要访问物理内存地址或者磁盘。
所以就需要一个内存管理单元（MMU）硬件把虚拟内存地址映射为物理内存地址。还有一个就是每一个进程的页表中都存储了从虚拟内存到物理内存页的映射关系。

### 页
这个存储了虚拟内存到物理内内存页映射关系的页实际上是个多层页。
正是因为有多层的页表结构可以用来转换虚拟地址，所以多个进程可以通过虚拟内存共享物理内存。这样是为什么，Linux fork创建子进程时，实际上只复制了父进程的页表。

</details>


------

### <span id="8">8.简述操作系统中的缺页中断？</span>
<details>
<summary>展开</summary>

操作系统采用的是虚拟内存地址映射物理内存地址的方式。

我们可以把虚拟内存看做磁盘的一部分，当进程频繁访问虚拟内存中的一片数据时，那么这部分数据就会被以**页**为单位的形式被缓存到**物理内存**中以加速**CPU访问速度**。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16241159458767.jpg)

所以虚拟内存中的虚拟页（Virtual Page，VP）可能处于以下的三种状态
* 未分配（Unallocated）：未分配的内存页是没有被进程申请使用的，也就是空闲的虚拟内存，不占用虚拟内存磁盘的任何空间
* 未缓存（Uncached）：仅加载到磁盘中的内存页
* 已缓存（Cached）：已经加载到主存中的内存页

如上图所示，图中绿色的虚拟内存页由主存中的物理内存页（Physical Page，PP）支撑，所以它是已经缓存过的，而黄色的虚拟内存页仅在磁盘中，所以没有被物理内存缓存。


### 操作系统中的缺页中断
当用户程序访问未被缓存的虚拟页时，也就是仅加载到磁盘中的内存页，硬件就会触发缺页中断（Page Fault，PF）。

![](https://github.com/binbinshan/Review-Up/blob/master/images/操作系统/16241162228820.jpg)

1. 在部分情况下，被访问的页面已经加载到了物理内存中，但是用户进程的页表（Page Table）并不存在该对应关系，这时我们只需要在页表中建立虚拟内存到物理内存的关系；
2. 在其他情况下，操作系统需要将磁盘上未被缓存的虚拟页加载到物理内存中。

### 页面替换技术
因为主内存的空间是有限的，当主内存中没有可使用的空间时，操作系统会从选择合适的物理内存页驱逐回磁盘，为新的内存页让出位置，选择待驱逐页的过程在操作系统中叫做页面替换（Page Replacement）。
缺页中断和页面替换技术都是操作系统调页算法（Paging）的一部分，该算法的目的就是充分利用内存资源作为磁盘的缓存以提高程序的运行效率。

</details>
